{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv5ecRoKNdo4"
      },
      "source": [
        "##Convert Annotation xml to txt "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "edt5r44cy1PP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Development Environment\n",
        "<br/>xml Parsing\n",
        "<br/>Detailed txt Transformation\n",
        "<br/>Detailed Sample 1000 txt Transformation\n",
        "<br/>Vehicle Class txt Transformation\n",
        "<br/>Class txt Transformation"
      ],
      "metadata": {
        "id": "1VLwXOhvy1TX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Nn0woLshzkTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Development Environment"
      ],
      "metadata": {
        "id": "HpSabBfFy1mw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spMLYXAfNryg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHrCWg2PZvCl"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C96X6AHGBng6"
      },
      "source": [
        "#xml Parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjRzL9bYl8xp"
      },
      "outputs": [],
      "source": [
        "xml_folder_path = '/content/drive/MyDrive/Aiffelthon/eda/xml_data'\n",
        "xml_folder_list = [xml_folder_path + '/train/train_part1_xml', xml_folder_path + '/train/train_part2_xml',\n",
        "                   xml_folder_path + '/validation/vaildation_xml']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def xml_file_list(xml_folder):\n",
        "  label = glob(xml_folder+'/labelXml'+'/*')\n",
        "  label = sorted(label, reverse=False)\n",
        "  label = sorted(label, key=len)\n",
        "  return label"
      ],
      "metadata": {
        "id": "7HsVSfuxiVNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFxHd-Eofgbj"
      },
      "outputs": [],
      "source": [
        "for i in xml_folder_list:\n",
        "  if 'train_part1' in i:\n",
        "    train_part1_label = xml_file_list(i)\n",
        "  elif 'train_part2' in i:\n",
        "    train_part2_label = xml_file_list(i)\n",
        "  elif 'validation' in i:\n",
        "    validation_label = xml_file_list(i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = train_part1_label + train_part2_label"
      ],
      "metadata": {
        "id": "X9n3Ntoj8CBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiYnZeNXOt--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62eaaedb-9267-494a-bc17-513f53e0523e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<annotation>\n",
            "\t<source>\n",
            "\t\t<filename>0.tif</filename>\n",
            "\t\t<origin>GF2/GF3</origin>\n",
            "\t</source>\n",
            "\t<research>\n",
            "\t\t<version>1.0</version>\n",
            "\t\t<provider>FAIR1M</provider>\n",
            "\t\t<author>Cyber</author>\n",
            "\t\t<pluginname>FAIR1M</pluginname>\n",
            "\t\t<pluginclass>object detection</pluginclass>\n",
            "\t\t<time>2021-07-21</time>\n",
            "\t</research>\n",
            "\t<size>\n",
            "\t\t<width>1500</width>\n",
            "\t\t<height>1500</height>\n",
            "\t\t<depth>3</depth>\n",
            "\t</size>\n",
            "\t<objects>\n",
            "\t\t<object>\n",
            "\t\t\t<coordinate>pixel</coordinate>\n",
            "\t\t\t<type>rectangle</type>\n",
            "\t\t\t<description>None</description>\n",
            "\t\t\t<possibleresult>\n",
            "\t\t\t\t<name>Liquid Cargo Ship</name>\n",
            "\t\t\t</possibleresult>\n",
            "\t\t\t<points>\n",
            "\t\t\t\t<point>1275.000000,458.000000</point>\n",
            "\t\t\t\t<point>1494.000000,88.000000</point>\n",
            "\t\t\t\t<point>1417.000000,43.000000</point>\n",
            "\t\t\t\t<point>1199.000000,414.000000</point>\n",
            "\t\t\t\t<point>1275.000000,458.000000</point>\n",
            "\t\t\t</points>\n",
            "\t\t</object>\n",
            "\t\t<object>\n",
            "\t\t\t<coordinate>pixel</coordinate>\n",
            "\t\t\t<type>rectangle</type>\n",
            "\t\t\t<description>None</description>\n",
            "\t\t\t<possibleresult>\n",
            "\t\t\t\t<name>Passenger Ship</name>\n",
            "\t\t\t</possibleresult>\n",
            "\t\t\t<points>\n",
            "\t\t\t\t<point>630.000000,403.000000</point>\n",
            "\t\t\t\t<point>586.000000,385.000000</point>\n",
            "\t\t\t\t<point>582.000000,397.000000</point>\n",
            "\t\t\t\t<point>625.000000,414.000000</point>\n",
            "\t\t\t\t<point>630.000000,403.000000</point>\n",
            "\t\t\t</points>\n",
            "\t\t</object>\n",
            "\t\t<object>\n",
            "\t\t\t<coordinate>pixel</coordinate>\n",
            "\t\t\t<type>rectangle</type>\n",
            "\t\t\t<description>None</description>\n",
            "\t\t\t<possibleresult>\n",
            "\t\t\t\t<name>Dry Cargo Ship</name>\n",
            "\t\t\t</possibleresult>\n",
            "\t\t\t<points>\n",
            "\t\t\t\t<point>591.000000,1531.000000</point>\n",
            "\t\t\t\t<point>761.000000,1377.000000</point>\n",
            "\t\t\t\t<point>718.000000,1332.000000</point>\n",
            "\t\t\t\t<point>549.000000,1486.000000</point>\n",
            "\t\t\t\t<point>591.000000,1531.000000</point>\n",
            "\t\t\t</points>\n",
            "\t\t</object>\n",
            "\t</objects>\n",
            "</annotation>\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import xml.etree.ElementTree\n",
        "\n",
        "tree = ET.parse(train_part1_label[0])\n",
        "root = tree.getroot()\n",
        "ET.dump(tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFdVIo1FvzVf",
        "outputId": "b43ffd0a-9729-4b9f-b03a-c181cec20701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filename 0.tif\n",
            "name Liquid Cargo Ship\n",
            "name Passenger Ship\n",
            "name Dry Cargo Ship\n"
          ]
        }
      ],
      "source": [
        "print(root[0][0].tag, root[0][0].text)\n",
        "for i in root[3]:\n",
        "  for child in i[3]:\n",
        "    print(child.tag, child.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tebm8WewA5hx",
        "outputId": "5bb1385c-13e8-4478-b2a9-78873e31bcca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liquid Cargo Ship\n",
            "1275.000000 458.000000\n",
            "1494.000000 88.000000\n",
            "1417.000000 43.000000\n",
            "1199.000000 414.000000\n",
            "1275.000000 458.000000\n",
            "Passenger Ship\n",
            "630.000000 403.000000\n",
            "586.000000 385.000000\n",
            "582.000000 397.000000\n",
            "625.000000 414.000000\n",
            "630.000000 403.000000\n",
            "Dry Cargo Ship\n",
            "591.000000 1531.000000\n",
            "761.000000 1377.000000\n",
            "718.000000 1332.000000\n",
            "549.000000 1486.000000\n",
            "591.000000 1531.000000\n"
          ]
        }
      ],
      "source": [
        "for i in root[3]:\n",
        "  for child in i[3]:\n",
        "    print(child.text)\n",
        "  for child in i[4]:\n",
        "    print(child.text.replace(\",\", \" \"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in root[3]:\n",
        "  str_context = ''\n",
        "  for j in range(0, 4):\n",
        "    str_context += i[4][j].text.replace(',', ' ') + ' '\n",
        "  for child in i[3]:\n",
        "    str_context += child.text.replace(\" \", \"\") + ' 0' + '\\n'\n",
        "    print(str_context, end = '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATMtl7bOi2bV",
        "outputId": "89134490-98df-4b40-9524-8173f6501c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1275.000000 458.000000 1494.000000 88.000000 1417.000000 43.000000 1199.000000 414.000000 LiquidCargoShip 0\n",
            "630.000000 403.000000 586.000000 385.000000 582.000000 397.000000 625.000000 414.000000 PassengerShip 0\n",
            "591.000000 1531.000000 761.000000 1377.000000 718.000000 1332.000000 549.000000 1486.000000 DryCargoShip 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in root[3]:\n",
        "  str_context = ''\n",
        "  for j in range(0, 4):\n",
        "    str_context += i[4][j].text.replace(',', ' ') + ' '\n",
        "  for child in i[3]:\n",
        "    if 'Dump Truck' == child.text or 'Cargo Truck' == child.text or  'Truck Tractor'  == child.text \\\n",
        "    or 'Tractor' == child.text or 'Excavator' == child.text or 'Trailer' == child.text or 'Van' == child.text \\\n",
        "    or 'Small Car' == child.text or 'Bus' == child.text or 'other-vehicle' == child.text:\n",
        "      str_context += 'vehicle' + ' 0' + '\\n'\n",
        "    elif 'A220' == child.text or 'A321' == child.text or 'A330' == child.text or  'A350' == child.text \\\n",
        "    or 'Boeing737' == child.text or 'Boeing747' == child.text or 'Boeing777' == child.text or 'Boeing787' == child.text \\\n",
        "    or 'ARJ21' == child.text or 'C919' == child.text or 'other-airplane' == child.text:\n",
        "      str_context += 'airplane' + ' 0' + '\\n'\n",
        "    elif 'Dry Cargo Ship' == child.text or 'Liquid Cargo Ship' == child.text or 'Motorboat' == child.text \\\n",
        "    or 'Fishing Boat' == child.text or 'Tugboat' == child.text or 'Engineering Ship' == child.text \\\n",
        "    or 'Warship' == child.text or 'Passenger Ship' == child.text or 'other-ship' == child.text:\n",
        "      str_context += 'ship' + ' 0' + '\\n'\n",
        "    print(str_context, end = '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6n4UlPls20P",
        "outputId": "901a127b-6c97-469e-d493-f20beaef2ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1275.000000 458.000000 1494.000000 88.000000 1417.000000 43.000000 1199.000000 414.000000 ship 0\n",
            "630.000000 403.000000 586.000000 385.000000 582.000000 397.000000 625.000000 414.000000 ship 0\n",
            "591.000000 1531.000000 761.000000 1377.000000 718.000000 1332.000000 549.000000 1486.000000 ship 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Detailed txt Transformation"
      ],
      "metadata": {
        "id": "0xk6U9imp5vM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRxPyfVsAzXW"
      },
      "outputs": [],
      "source": [
        "def xml2txt(path_xmls, path_txt):\n",
        "  tree = ET.parse(path_xmls)\n",
        "  root = tree.getroot()\n",
        "  str_filename = path_txt + root[0][0].text[0:root[0][0].text.find('.')] + '.txt'\n",
        "  lst_context = []\n",
        "  for i in root[3]:\n",
        "    str_context = ''\n",
        "    for j in range(0, 4):\n",
        "      str_context += i[4][j].text.replace(',', ' ') + ' '\n",
        "    for child in i[3]:\n",
        "      str_context += child.text.replace(\" \", \"\") + ' 0' + '\\n'\n",
        "    lst_context.append(str_context)\n",
        "  return str_filename, lst_context"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_path_fair1m_train2 = train_part2_label\n",
        "list_path_fair1m_val = validation_label\n",
        "path_dataset_txt_train = '/content/drive/MyDrive/Aiffelthon/mmrotate/data/fair1m2.0/train_detailed/'\n",
        "path_dataset_txt_val = '/content/drive/MyDrive/Aiffelthon/mmrotate/data/fair1m2.0/val_detailed/'\n",
        "\n",
        "for fn in range(len(list_path_fair1m_train2)):\n",
        "  txt_filename, txt_content = xml2txt(list_path_fair1m_train2[fn], path_dataset_txt_train)\n",
        "  with open(txt_filename, 'w') as file:\n",
        "    for i in range(len(txt_content)):\n",
        "        file.write(txt_content[i])\n",
        "  file.close()\n",
        "\n",
        "for fn in range(len(list_path_fair1m_val)):\n",
        "  txt_filename, txt_content = xml2txt(list_path_fair1m_val[fn], path_dataset_txt_val)\n",
        "  with open(txt_filename, 'w') as file:\n",
        "    for i in range(len(txt_content)):\n",
        "        file.write(txt_content[i])\n",
        "  file.close()    "
      ],
      "metadata": {
        "id": "CZ5FXHIfPkHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Detailed Sample 1000 txt Transformation"
      ],
      "metadata": {
        "id": "Z-4mupKuSXU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_label[8268:9268]"
      ],
      "metadata": {
        "id": "_RFdRsIMSuRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_label[:100]"
      ],
      "metadata": {
        "id": "fNtjHDyHS_oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_path_fair1m_train = train_label[8268:9268]\n",
        "list_path_fair1m_val = validation_label[:1000]\n",
        "path_dataset_txt_train = '/content/drive/MyDrive/Aiffelthon/mmrotate/data/fair1m2.0/train_1000/'\n",
        "path_dataset_txt_val = '/content/drive/MyDrive/Aiffelthon/mmrotate/data/fair1m2.0/val_100/'\n",
        "\n",
        "for fn in range(len(list_path_fair1m_train2)):\n",
        "  txt_filename, txt_content = xml2txt(list_path_fair1m_train2[fn], path_dataset_txt_train)\n",
        "  with open(txt_filename, 'w') as file:\n",
        "    for i in range(len(txt_content)):\n",
        "        file.write(txt_content[i])\n",
        "  file.close()\n",
        "\n",
        "for fn in range(len(list_path_fair1m_val)):\n",
        "  txt_filename, txt_content = xml2txt(list_path_fair1m_val[fn], path_dataset_txt_val)\n",
        "  with open(txt_filename, 'w') as file:\n",
        "    for i in range(len(txt_content)):\n",
        "        file.write(txt_content[i])\n",
        "  file.close()    "
      ],
      "metadata": {
        "id": "pSQhQJFySub2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vehicle Class txt Transformation"
      ],
      "metadata": {
        "id": "46jNdO4PS37V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xml2txt(path_xmls, path_txt):\n",
        "  tree = ET.parse(path_xmls)\n",
        "  root = tree.getroot()\n",
        "  str_filename = path_txt + root[0][0].text[0:root[0][0].text.find('.')] + '.txt'\n",
        "  lst_context = []\n",
        "  for i in root[3]:\n",
        "    str_context = ''\n",
        "    for j in range(0, 4):\n",
        "      str_context += i[4][j].text.replace(',', ' ') + ' '\n",
        "    for child in i[3]:\n",
        "      if 'Dump Truck' == child.text or 'Cargo Truck' == child.text or  'Truck Tractor'  == child.text \\\n",
        "      or 'Tractor' == child.text or 'Excavator' == child.text or 'Trailer' == child.text or 'Van' == child.text \\\n",
        "      or 'Small Car' == child.text or 'Bus' == child.text or 'other-vehicle' == child.text:\n",
        "        str_context += 'vehicle' + ' 0' + '\\n'\n",
        "      elif 'A220' == child.text or 'A321' == child.text or 'A330' == child.text or  'A350' == child.text \\\n",
        "      or 'Boeing737' == child.text or 'Boeing747' == child.text or 'Boeing777' == child.text or 'Boeing787' == child.text \\\n",
        "      or 'ARJ21' == child.text or 'C919' == child.text or 'other-airplane' == child.text:\n",
        "        str_context += 'airplane' + ' 0' + '\\n'\n",
        "      elif 'Dry Cargo Ship' == child.text or 'Liquid Cargo Ship' == child.text or 'Motorboat' == child.text \\\n",
        "      or 'Fishing Boat' == child.text or 'Tugboat' == child.text or 'Engineering Ship' == child.text \\\n",
        "      or 'Warship' == child.text or 'Passenger Ship' == child.text or 'other-ship' == child.text:\n",
        "        str_context += 'ship' + ' 0' + '\\n'\n",
        "    if 'vehicle' in str_context:\n",
        "      lst_context.append(str_context)\n",
        "  return str_filename, lst_context"
      ],
      "metadata": {
        "id": "_YHHdoAPS4B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_path_fair1m_train = train_part1_label\n",
        "list_path_fair1m_val = validation_label\n",
        "path_dataset_txt_train = '/content/drive/MyDrive/Aiffelthon/mmrotate/data/fair1m2.0/train_only_vehicle/'\n",
        "path_dataset_txt_val = '/content/drive/MyDrive/Aiffelthon/mmrotate/data/fair1m2.0/val_only_vehicle/'\n",
        "\n",
        "\n",
        "for fn in range(len(list_path_fair1m_train2)):\n",
        "  txt_filename, txt_content = xml2txt(list_path_fair1m_train[fn], path_dataset_txt_train2)\n",
        "  with open(txt_filename, 'w') as file:\n",
        "    for i in range(len(txt_content)):\n",
        "        file.write(txt_content[i])\n",
        "  file.close()\n",
        "\n",
        "for fn in range(len(list_path_fair1m_val)):\n",
        "  txt_filename, txt_content = xml2txt(list_path_fair1m_val[fn], path_dataset_txt_val)\n",
        "  with open(txt_filename, 'w') as file:\n",
        "    for i in range(len(txt_content)):\n",
        "        file.write(txt_content[i])\n",
        "  file.close()    "
      ],
      "metadata": {
        "id": "dXp7tveES4Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class txt Transformation"
      ],
      "metadata": {
        "id": "kcF5KNT-9z2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xml2txt(path_xmls, path_txt):\n",
        "  tree = ET.parse(path_xmls)\n",
        "  root = tree.getroot()\n",
        "  str_filename = path_txt + root[0][0].text[0:root[0][0].text.find('.')] + '.txt'\n",
        "  lst_context = []\n",
        "  for i in root[3]:\n",
        "    str_context = ''\n",
        "    for j in range(0, 4):\n",
        "      str_context += i[4][j].text.replace(',', ' ') + ' '\n",
        "    for child in i[3]:\n",
        "      if 'Dump Truck' == child.text or 'Cargo Truck' == child.text or  'Truck Tractor' == child.text \\\n",
        "      or 'Tractor' == child.text or 'Excavator' == child.text or 'Trailer' == child.text or 'Van' == child.text \\\n",
        "      or 'Small Car' == child.text or 'Bus' == child.text or 'other-vehicle' == child.text:\n",
        "        str_context += 'vehicle' + ' 0' + '\\n'\n",
        "      elif 'A220' == child.text or 'A321' == child.text or 'A330' == child.text or  'A350' == child.text \\\n",
        "      or 'Boeing737' == child.text or 'Boeing747' == child.text or 'Boeing777' == child.text or 'Boeing787' == child.text \\\n",
        "      or 'ARJ21' == child.text or 'C919' == child.text or 'other-airplane' == child.text:\n",
        "        str_context += 'airplane' + ' 0' + '\\n'\n",
        "      elif 'Dry Cargo Ship' == child.text or 'Liquid Cargo Ship' == child.text or 'Motorboat' == child.text \\\n",
        "      or 'Fishing Boat' == child.text or 'Tugboat' == child.text or 'Engineering Ship' == child.text \\\n",
        "      or 'Warship' == child.text or 'Passenger Ship' == child.text or 'other-ship' == child.text:\n",
        "        str_context += 'ship' + ' 0' + '\\n'\n",
        "    if 'vehicle' in str_context or 'airplane' in str_context or 'ship' in str_context:\n",
        "      lst_context.append(str_context)\n",
        "  return str_filename, lst_context"
      ],
      "metadata": {
        "id": "kjPs6EIv9yMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_path_fair1m_train = train_part1_label\n",
        "list_path_fair1m_val = validation_label\n",
        "path_dataset_txt_train = '/content/drive/MyDrive/Aiffelthon/mmrotate/data/fair1m2.0/train_super/'\n",
        "path_dataset_txt_val = '/content/drive/MyDrive/Aiffelthon/mmrotate/data/fair1m2.0/val_super/'\n",
        "\n",
        "for fn in range(len(list_path_fair1m_train)):\n",
        "  txt_filename, txt_content = xml2txt(list_path_fair1m_train[fn], path_dataset_txt_train2)\n",
        "  with open(txt_filename, 'w') as file:\n",
        "    for i in range(len(txt_content)):\n",
        "        file.write(txt_content[i])\n",
        "  file.close()\n",
        "\n",
        "for fn in range(len(list_path_fair1m_val)):\n",
        "  txt_filename, txt_content = xml2txt(list_path_fair1m_val[fn], path_dataset_txt_val)\n",
        "  with open(txt_filename, 'w') as file:\n",
        "    for i in range(len(txt_content)):\n",
        "        file.write(txt_content[i])\n",
        "  file.close()    "
      ],
      "metadata": {
        "id": "2osvHMc79yO6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}